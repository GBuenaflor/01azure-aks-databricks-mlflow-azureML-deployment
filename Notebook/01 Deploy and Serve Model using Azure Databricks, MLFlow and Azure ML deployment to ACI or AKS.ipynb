{"cells":[{"cell_type":"markdown","source":["# 01 Deploy and Serve Model using Azure Databricks, MLFlow and Azure ML deployment to ACI or AKS.\n<br>\nUsing MLflow and Azure ML to deploy and quey model to ACI or AKS environments.\n<br>\n<br>\n* Create an Azure ML Workspace\n* Build an Azure Container Image for model deployment\n* Deploy the model to \"staging\" using Azure Container Instances (ACI)\n* Query the deployed model in \"staging\"\n* Deploy the model to production using Azure Kubernetes Service (AKS)\n* Query the deployed model in production\n* Update the production deployment\n* Clean up the deployments\n\n**Required Libraries via PyPI **:\n* `mlflow==1.7.0`  \n* `azureml-sdk==1.2.0` \n\n<br>\nCopyright (c) Microsoft Corporation. All rights reserved.\n<br>\nLicensed under the MIT License.\n<br>"],"metadata":{}},{"cell_type":"markdown","source":["### 1. Create or load an Azure ML Workspace\nBefore models can be deployed to Azure ML, you must create or obtain an Azure ML Workspace. The `azureml.core.Workspace.create()` function will load a workspace of a specified name or create one if it does not already exist. For more information about creating an Azure ML Workspace, see the [Azure ML Workspace management documentation](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-manage-workspace)."],"metadata":{}},{"cell_type":"code","source":["\nimport azureml\nfrom azureml.core import Workspace\nfrom azureml.core.authentication import InteractiveLoginAuthentication\n\nworkspace_name = \"az-workspace01\"\nworkspace_location=\"eastus\"\nresource_group = \"Env-DataBricks-RG\"\nsubscription_id = \"xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\"  # Replace with your subscription id\n \nauth = InteractiveLoginAuthentication(tenant_id=\"xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\") # Replace with your tenant id\n\nworkspace = Workspace.create(name = workspace_name,\n                             location = workspace_location,\n                             resource_group = resource_group,\n                             subscription_id = subscription_id,\n                             auth = auth,\n                             exist_ok=True)\n"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":["### 2. Train the Diabetes Model and build a Container Image for the trained model"],"metadata":{}},{"cell_type":"code","source":["# View the diabetes dataset from scikit-learn\nfrom sklearn.datasets import load_diabetes\n\ndiabetes = load_diabetes()  \n\nprint('diabetes.keys: ', diabetes.keys())\nprint('diabetes.data: ', diabetes.data)\nprint('diabetes.target: ', diabetes.target)"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":["#### Train the Data Model\n\nWe will uses the `diabetes` dataset in scikit-learn and predicts the progression metric (a quantitative measure of disease progression after one year after) based on BMI, blood pressure, etc. We will uses the scikit-learn ElasticNet linear regression model. We will use MLflow to log  metrics, parameters, artifacts and model."],"metadata":{}},{"cell_type":"code","source":["import os\nimport warnings\nimport sys\nfrom random import random\nimport pandas as pd\nimport numpy as np\nfrom itertools import cycle\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.linear_model import lasso_path, enet_path\nfrom sklearn import datasets\n# Import mlflow\nimport mlflow\nimport mlflow.sklearn\n\n# Load Diabetes datasets\ndiabetes = datasets.load_diabetes()\nX = diabetes.data\ny = diabetes.target\n\n# Create pandas DataFrame for sklearn ElasticNet linear_model\nY = np.array([y]).transpose()\nd = np.concatenate((X, Y), axis=1)\ncols = ['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6', 'progression']\ndata = pd.DataFrame(d, columns=cols)\n\ndef train_diabetes(data, in_alpha, in_l1_ratio):\n  # Evaluate metrics\n  def eval_metrics(actual, pred):\n      rmse = np.sqrt(mean_squared_error(actual, pred))\n      mae = mean_absolute_error(actual, pred)\n      r2 = r2_score(actual, pred)\n      return rmse, mae, r2\n\n  warnings.filterwarnings(\"ignore\")\n  np.random.seed(40)\n\n  # Split the data into training and test sets. (0.75, 0.25) split.\n  train, test = train_test_split(data)\n\n  # The predicted column is \"progression\" which is a quantitative measure of disease progression one year after baseline\n  train_x = train.drop([\"progression\"], axis=1)\n  test_x = test.drop([\"progression\"], axis=1)\n  train_y = train[[\"progression\"]]\n  test_y = test[[\"progression\"]]\n\n  if float(in_alpha) is None:\n    alpha = 0.05\n  else:\n    alpha = float(in_alpha)\n    \n  if float(in_l1_ratio) is None:\n    l1_ratio = 0.05\n  else:\n    l1_ratio = float(in_l1_ratio)\n  \n  # Start an MLflow run; the \"with\" keyword ensures we'll close the run even if this cell crashes\n  with mlflow.start_run() as run:\n    lr = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, random_state=42)\n    lr.fit(train_x, train_y)\n\n    predicted_qualities = lr.predict(test_x)\n\n    (rmse, mae, r2) = eval_metrics(test_y, predicted_qualities)\n\n    # Print out ElasticNet model metrics\n    print(\"Elasticnet model (alpha=%f, l1_ratio=%f):\" % (alpha, l1_ratio))\n    print(\"  RMSE: %s\" % rmse)\n    print(\"  MAE: %s\" % mae)\n    print(\"  R2: %s\" % r2)\n\n    # Log mlflow attributes for mlflow UI\n    mlflow.log_param(\"alpha\", alpha)\n    mlflow.log_param(\"l1_ratio\", l1_ratio)\n    mlflow.log_metric(\"rmse\", rmse)\n    mlflow.log_metric(\"r2\", r2)\n    mlflow.log_metric(\"mae\", mae)\n    mlflow.sklearn.log_model(lr, \"model\")\n    rand_int = int(random()*10000)\n    modelpath = \"/dbfs/mlflow/test_diabetes/model-%f-%f-%f\" % (alpha, l1_ratio, rand_int)\n    mlflow.sklearn.save_model(lr, modelpath)\n    \n    run_id = run.info.run_id\n    print('Run ID: ', run_id)\n    model_uri = \"runs:/\" + run_id + \"/model\"\n    print('model_uri: ', model_uri)\n    \n    return run_id, model_uri\n    \nrun_id, model_uri = train_diabetes(data, 0.01, 1)"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":["#### Use MLflow to build a Container Image for the trained model\n\nUse the `mlflow.azuereml.build_image` function to build an Azure Container Image for the trained MLflow model. This function also registers the MLflow model with a specified Azure ML workspace. The resulting image can be deployed to Azure Container Instances (ACI) or Azure Kubernetes Service (AKS) for real-time serving."],"metadata":{}},{"cell_type":"code","source":["import mlflow.azureml\n\nmodel_image, azure_model = mlflow.azureml.build_image(model_uri=model_uri, \n                                                      workspace=workspace,\n                                                      model_name=\"model\",\n                                                      image_name=\"model\",\n                                                      description=\"Sklearn ElasticNet image for predicting diabetes progression\",\n                                                      synchronous=False)\nmodel_image.wait_for_creation(show_output=True)"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":["### 3. Create an ACI webservice deployment\n\nThe [ACI platform](https://docs.microsoft.com/en-us/azure/container-instances/) is the recommended environment for staging and developmental model deployments. Using the Azure ML SDK, deploy the Container Image for the trained MLflow model to ACI."],"metadata":{}},{"cell_type":"code","source":["from azureml.core.webservice import AciWebservice, Webservice\n\ndev_webservice_name = \"diabetes-model\"\ndev_webservice_deployment_config = AciWebservice.deploy_configuration()\ndev_webservice = Webservice.deploy_from_image(name=dev_webservice_name, image=model_image, deployment_config=dev_webservice_deployment_config, workspace=workspace)\ndev_webservice.wait_for_deployment()"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["# Create a sample data \nfrom sklearn import datasets\nimport pandas as pd\nimport numpy as np\nimport requests\nimport json\n\ndiabetes = datasets.load_diabetes()\nX = diabetes.data\ny = diabetes.target\nY = np.array([y]).transpose()\nd = np.concatenate((X, Y), axis=1)\ncols = ['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6', 'progression']\ndata = pd.DataFrame(d, columns=cols)\nsample = data.drop([\"progression\"], axis=1).iloc[[0]]\n                                                 \nquery_input = sample.to_json(orient='split')\nquery_input = eval(query_input)\nquery_input.pop('index', None)\n\n\n# sending an HTTP request\ndef query_endpoint_example(scoring_uri, inputs, service_key=None):\n  headers = {\n    \"Content-Type\": \"application/json\",\n  }\n  if service_key is not None:\n    headers[\"Authorization\"] = \"Bearer {service_key}\".format(service_key=service_key)\n    \n  print(\"Sending batch prediction request with inputs: {}\".format(inputs))\n  response = requests.post(scoring_uri, data=json.dumps(inputs), headers=headers)\n  preds = json.loads(response.text)\n  print(\"Received response: {}\".format(preds))\n  return preds"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["dev_webservice.scoring_uri\ndev_prediction = query_endpoint_example(scoring_uri=dev_webservice.scoring_uri, inputs=query_input)"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":["### 4. Deploy the model to production using [Azure Kubernetes Service (AKS)](https://azure.microsoft.com/en-us/services/kubernetes-service/)"],"metadata":{}},{"cell_type":"markdown","source":["#### Option 1: Create a new AKS cluster\n\nIf you do not have an active AKS cluster for model deployment, create one using the Azure ML SDK."],"metadata":{}},{"cell_type":"code","source":["# I didn't use this option, Terraform created the Kubernentes Cluster\n\nfrom azureml.core.compute import AksCompute, ComputeTarget\n\n# Use the default configuration (you can also provide parameters to customize this)\nprov_config = AksCompute.provisioning_configuration()\n\naks_cluster_name = \"aks-cluster\" \n# Create the cluster\naks_target = ComputeTarget.create(workspace = workspace, \n                                  name = aks_cluster_name, \n                                  provisioning_configuration = prov_config)\n\n# Wait for the create process to complete\naks_target.wait_for_completion(show_output = True)\nprint(aks_target.provisioning_state)\nprint(aks_target.provisioning_errors)"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":["#### Option 2: Connect to an existing AKS cluster in your workspace"],"metadata":{}},{"cell_type":"code","source":["from azureml.core.compute import AksCompute, ComputeTarget\n \n# Give the cluster a local name\naks_cluster_name = \"az-k8s\"\n\n# Attach the cluster to your workgroup\nattach_config = AksCompute.attach_configuration(resource_group = \"Env-DataBricks-RG\",\n                                                cluster_name = aks_cluster_name,\n                                               cluster_purpose = AksCompute.ClusterPurpose.DEV_TEST)  \n#  cluster_purpose = AksCompute.ClusterPurpose.DEV_TEST\n#  At least 3 machine(s) are required for cluster with purpose 'FastProd'\n\naks_target = ComputeTarget.attach(workspace=workspace, \n                                  name=aks_cluster_name, \n                                  attach_configuration=attach_config)\n\naks_target.wait_for_completion(True)\n\nprint(aks_target.provisioning_state)\nprint(aks_target.provisioning_errors)"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":["### 5. Deploy to the model's image to the specified AKS cluster"],"metadata":{}},{"cell_type":"code","source":["\nfrom azureml.core.webservice import Webservice, AksWebservice\nfrom azureml.core import Image\n\n# Set configuration and service name\nprod_webservice_name = \"diabetes-model-prod\"\nprod_webservice_deployment_config = AksWebservice.deploy_configuration()\nimage_name =\"model\" \n  \n  \nimage = Image(name=image_name, workspace=workspace)\n\n\n# Deploy from image\nprod_webservice = Webservice.deploy_from_image(workspace = workspace, \n                                               name = prod_webservice_name,\n                                               image = image, #model_image,\n                                               deployment_config = prod_webservice_deployment_config,\n                                               deployment_target = aks_target)\n"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"code","source":["# Wait for the deployment to complete\nprod_webservice.wait_for_deployment(show_output = True)"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":["We can evaluate the sample data by sending an HTTP request. Query the AKS webservice's scoring endpoint by sending an HTTP POST request that includes the input vector. The production AKS deployment may require an authorization token (service key) for queries. Include this key in the HTTP request header."],"metadata":{}},{"cell_type":"code","source":["# Test the Webservice\n\nimport requests\nimport json\n\ndef query_endpoint_example(scoring_uri, inputs, service_key=None):\n  headers = {\n    \"Content-Type\": \"application/json\",\n  }\n  if service_key is not None:\n    headers[\"Authorization\"] = \"Bearer {service_key}\".format(service_key=service_key)\n    \n  print(\"Sending batch prediction request with inputs: {}\".format(inputs))\n  response = requests.post(scoring_uri, data=json.dumps(inputs), headers=headers)\n  preds = json.loads(response.text)\n  print(\"Received response: {}\".format(preds))\n  return preds"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"code","source":["# Create data\n\nimport pandas as pd\nimport numpy as np\n\nX = diabetes.data\ny = diabetes.target\nY = np.array([y]).transpose()\nd = np.concatenate((X, Y), axis=1)\ncols = ['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6', 'progression']\ndata = pd.DataFrame(d, columns=cols)\nsample = data.drop([\"progression\"], axis=1).iloc[[0]]\n                                                 \nquery_input = sample.to_json(orient='split')\nquery_input = eval(query_input)\nquery_input.pop('index', None)\n\n#View the webservice prediction\n\n\nprod_scoring_uri = prod_webservice.scoring_uri\nprod_service_key = prod_webservice.get_keys()[0] if len(prod_webservice.get_keys()) > 0 else None\n \nprint(\"prod_scoring_uri:\") \nprint(prod_scoring_uri)\n\nprint(\"prod_service_key:\")\nprint(prod_service_key)\n\n\nprint(\"prod_prediction1:\")\nprod_prediction1 = query_endpoint_example(scoring_uri=prod_scoring_uri, service_key=prod_service_key, inputs=query_input)\n \n"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"markdown","source":["### 6. Update the production deployment\n\nTrain a new model with different hyperparameters and deploy the new model to production."],"metadata":{}},{"cell_type":"code","source":["import mlflow.azureml\n\n# Train a new model with different hyperparameters\nrun_id_new, model_uri = train_diabetes(data, 0.01, 0.9)\n\n# Build a container image for the new trained model\nmodel_image_updated, azure_model_updated = mlflow.azureml.build_image(model_uri=model_uri, \n                                                                      workspace=workspace,\n                                                                      model_name=\"model-updated\",\n                                                                      image_name=\"model-updated\",\n                                                                      description=\"Sklearn ElasticNet image for predicting diabetes progression\",\n                                                                      synchronous=False)\nmodel_image_updated.wait_for_creation(show_output=True)"],"metadata":{},"outputs":[],"execution_count":26},{"cell_type":"markdown","source":["### 7. Deploy the new model's image to the AKS cluster\n\nUsing the [`azureml.core.webservice.AksWebservice.update()`](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.webservice.akswebservice?view=azure-ml-py#update) function, replace the deployment's existing model image with the new model image."],"metadata":{}},{"cell_type":"code","source":["prod_webservice.update(image=model_image_updated)\nprod_webservice.wait_for_deployment(show_output = True)"],"metadata":{},"outputs":[],"execution_count":28},{"cell_type":"markdown","source":["We can now query the updated model and compare the results."],"metadata":{}},{"cell_type":"code","source":["prod_prediction2 = query_endpoint_example(scoring_uri=prod_scoring_uri, service_key=prod_service_key, inputs=query_input)\nprint(\"Run ID: {} Prediction: {}\".format(run_id, prod_prediction1)) \nprint(\"Run ID: {} Prediction: {}\".format(run_id_new, prod_prediction2))"],"metadata":{},"outputs":[],"execution_count":30},{"cell_type":"markdown","source":["### 8. Clean up the deployments"],"metadata":{}},{"cell_type":"markdown","source":["We can now terminate the \"staging\" ACI webservice. Because ACI manages compute resources on your behalf, deleting the \"dev\" ACI webservice will remove all resources associated with the \"staging\" model deployment"],"metadata":{}},{"cell_type":"code","source":["dev_webservice.delete()\nprod_webservice.delete()\naks_target.delete()"],"metadata":{},"outputs":[],"execution_count":33}],"metadata":{"name":"01Azure-Machine Learning Deployment - ACI or AKS Environment","notebookId":1505999143950237},"nbformat":4,"nbformat_minor":0}
